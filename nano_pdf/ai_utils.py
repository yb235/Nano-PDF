import json
import os
import re
from textwrap import dedent
from typing import List, Tuple, Optional, Dict, Any

from PIL import Image
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

def get_client():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY not found in environment variables")
    return genai.Client(api_key=api_key)

def generate_edited_slide(
    target_image: Image.Image,
    style_reference_images: List[Image.Image],
    full_text_context: str,
    user_prompt: str,
    resolution: str = "4K",
    enable_search: bool = False
) -> Tuple[Image.Image, Optional[str]]:
    """
    Sends the target image, style refs, and text context to Gemini 3 Pro Image.
    Returns tuple of (generated PIL Image, optional text response).
    """
    client = get_client()

    # Construct the prompt
    prompt_parts = []

    prompt_parts.append(user_prompt)
    prompt_parts.append(target_image)

    if style_reference_images:
        prompt_parts.append("Match the visual style (fonts, colors, layout) of these reference images:")
        for img in style_reference_images:
            prompt_parts.append(img)

    if full_text_context:
        prompt_parts.append(f"DOCUMENT CONTEXT:\n{full_text_context}\n")

    # Build config - allow both text and image output
    config = types.GenerateContentConfig(
        response_modalities=['TEXT', 'IMAGE'],
        image_config=types.ImageConfig(
            image_size=resolution
        )
    )
    if enable_search:
        config.tools = [{"google_search": {}}]

    # Call the model
    try:
        response = client.models.generate_content(
            model='gemini-3-pro-image-preview',
            contents=prompt_parts,
            config=config
        )
    except Exception as e:
        error_msg = str(e).lower()
        if "quota" in error_msg or "billing" in error_msg or "payment" in error_msg:
            raise RuntimeError(
                "Gemini API Error: This tool requires a PAID API key with billing enabled.\n"
                "Free tier keys do not support image generation. Please:\n"
                "1. Visit https://aistudio.google.com/api-keys\n"
                "2. Enable billing on your Google Cloud project\n"
                f"Original error: {e}"
            )
        elif "api key" in error_msg or "authentication" in error_msg or "unauthorized" in error_msg:
            raise RuntimeError(
                "Gemini API Error: Invalid API key.\n"
                "Please check that your GEMINI_API_KEY environment variable is set correctly.\n"
                f"Original error: {e}"
            )
        else:
            raise RuntimeError(f"Gemini API Error: {e}")

    # Extract image and text from the response
    generated_image = None
    response_text = None
    if response.candidates and response.candidates[0].content.parts:
        for part in response.candidates[0].content.parts:
            if part.inline_data:
                # Convert bytes to PIL Image
                from io import BytesIO
                generated_image = Image.open(BytesIO(part.inline_data.data))
            elif part.text:
                response_text = part.text

    if not generated_image:
        raise RuntimeError("No image generated by the model.")

    return generated_image, response_text

def generate_new_slide(
    style_reference_images: List[Image.Image],
    user_prompt: str,
    full_text_context: str = "",
    resolution: str = "4K",
    enable_search: bool = False
) -> Tuple[Image.Image, Optional[str]]:
    """
    Generates a completely new slide based on style references and a prompt.
    Returns tuple of (generated PIL Image, optional text response).
    """
    client = get_client()

    # Construct the prompt
    prompt_parts = []

    prompt_parts.append(user_prompt)

    if style_reference_images:
        prompt_parts.append("Match the visual style (fonts, colors, layout) of these reference images:")
        for img in style_reference_images:
            prompt_parts.append(img)

    if full_text_context:
        prompt_parts.append(f"DOCUMENT CONTEXT:\n{full_text_context}\n")

    # Build config - allow both text and image output
    config = types.GenerateContentConfig(
        response_modalities=['TEXT', 'IMAGE'],
        image_config=types.ImageConfig(
            image_size=resolution
        )
    )
    if enable_search:
        config.tools = [{"google_search": {}}]

    # Call the model
    try:
        response = client.models.generate_content(
            model='gemini-3-pro-image-preview',
            contents=prompt_parts,
            config=config
        )
    except Exception as e:
        error_msg = str(e).lower()
        if "quota" in error_msg or "billing" in error_msg or "payment" in error_msg:
            raise RuntimeError(
                "Gemini API Error: This tool requires a PAID API key with billing enabled.\n"
                "Free tier keys do not support image generation. Please:\n"
                "1. Visit https://aistudio.google.com/api-keys\n"
                "2. Enable billing on your Google Cloud project\n"
                f"Original error: {e}"
            )
        elif "api key" in error_msg or "authentication" in error_msg or "unauthorized" in error_msg:
            raise RuntimeError(
                "Gemini API Error: Invalid API key.\n"
                "Please check that your GEMINI_API_KEY environment variable is set correctly.\n"
                f"Original error: {e}"
            )
        else:
            raise RuntimeError(f"Gemini API Error: {e}")

    # Extract image and text from the response
    generated_image = None
    response_text = None
    if response.candidates and response.candidates[0].content.parts:
        for part in response.candidates[0].content.parts:
            if part.inline_data:
                # Convert bytes to PIL Image
                from io import BytesIO
                generated_image = Image.open(BytesIO(part.inline_data.data))
            elif part.text:
                response_text = part.text

    if not generated_image:
        raise RuntimeError("No image generated by the model.")

    return generated_image, response_text

def extract_chart_data_from_slide(
    slide_image: Image.Image,
    page_number: Optional[int] = None,
    full_text_context: str = "",
    max_charts: int = 4,
    enable_search: bool = False,
    temperature: float = 0.2,
) -> List[Dict[str, Any]]:
    """
    Uses Nano Banana to detect charts on a slide and approximate their data.
    Returns a list of dictionaries describing each chart (type, bbox, data).
    """
    client = get_client()

    context_snippet = (full_text_context or "")[:5000]
    max_charts = max(1, min(max_charts, 8))

    instructions = dedent(
        f"""
        You are Nano Banana, an ultra-precise presentation analyst.
        Inspect the provided slide image and emit STRICT JSON describing up to {max_charts} data visualizations.

        JSON schema:
        {{
          "charts": [
             {{
               "id": "chart-1",
               "chart_type": "bar|column|line|area|pie|scatter",
               "title": "Optional chart title",
               "bounding_box": {{"x":0.0,"y":0.0,"width":0.0,"height":0.0}},  # normalized 0-1 relative to image width/height
               "x_axis_label": "Optional label",
               "y_axis_label": "Optional label",
               "categories": ["Category 1", "Category 2"],
               "series": [
                 {{"name": "Series A", "values": [1.0, 2.0]}}
               ]
             }}
          ]
        }}

        Requirements:
        - Only describe real charts/graphs present on the slide.
        - Bounding boxes must tightly frame the visualization (0-1 floats).
        - categories[i] aligns with each value column-wise.
        - Series should include numeric values (float) approximating the visual data.
        - Respond with valid JSON only (no markdown, no commentary).
        """
    ).strip()

    prompt_parts: List[Any] = [instructions, slide_image]

    if page_number is not None:
        prompt_parts.append(f"Page number: {page_number}")
    if context_snippet:
        prompt_parts.append(f"DOCUMENT CONTEXT:\n{context_snippet}")

    config = types.GenerateContentConfig(
        response_modalities=['TEXT'],
        temperature=temperature,
        top_p=0.8,
        max_output_tokens=2048,
    )
    if enable_search:
        config.tools = [{"google_search": {}}]

    response = client.models.generate_content(
        model='gemini-3-pro-image-preview',
        contents=prompt_parts,
        config=config
    )

    raw_text = _extract_first_text(response)
    if not raw_text:
        return []

    payload = _parse_json_response(raw_text)
    charts = payload.get("charts", [])
    if isinstance(charts, list):
        return charts
    return []


def _extract_first_text(response) -> str:
    if not response or not getattr(response, "candidates", None):
        return ""
    for candidate in response.candidates:
        content = getattr(candidate, "content", None)
        if not content:
            continue
        for part in getattr(content, "parts", []):
            if part.text:
                return part.text
    return ""


def _parse_json_response(raw_text: str) -> Dict[str, Any]:
    cleaned = raw_text.strip()
    if cleaned.startswith("```"):
        cleaned = re.sub(r"^```(?:json)?", "", cleaned, flags=re.IGNORECASE).strip()
        cleaned = re.sub(r"```$", "", cleaned).strip()
    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        # Attempt to salvage by locating the first/last braces
        start = cleaned.find("{")
        end = cleaned.rfind("}")
        if start != -1 and end != -1 and end > start:
            snippet = cleaned[start : end + 1]
            try:
                return json.loads(snippet)
            except json.JSONDecodeError:
                pass
    return {"charts": []}
